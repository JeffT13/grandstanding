{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, string, os\n",
    "import numpy as np\n",
    "from scipy.stats import describe\n",
    "\n",
    "trans_path = './bigtest/oyez/'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./bigtest/set_dict.json') as f:\n",
    "    set_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_oyez(case, pth=trans_path):    \n",
    "    f = open(pth+case+'.txt','r')\n",
    "    k = f.readlines()\n",
    "    f.close()\n",
    "    oyez = []\n",
    "    wd = []\n",
    "    for u in k:\n",
    "        if len(u)>=3: # check for filler lines\n",
    "            t0, t1, spkr = u.split(' ')[0:3]\n",
    "            text = u.split(spkr)[-1]\n",
    "            oyez.append(text)\n",
    "            temp = text.split(' ')\n",
    "            stp = ((float(t1)-float(t0))/len(temp))\n",
    "            seq = [float(t0)+(stp*i) for i in range(len(temp))]\n",
    "            for idx, time in enumerate(seq):\n",
    "                if temp[idx]!='':\n",
    "                    wd.append([temp[idx], time, time+(stp-.0001)])       \n",
    "    return oyez, wd\n",
    "\n",
    "def clean_trans(lst):\n",
    "    clean  = ''.join(lst)\n",
    "    c = clean.translate(str.maketrans('', '', string.punctuation))\n",
    "    c = c.replace('\\n', '')\n",
    "    c = c.lower()\n",
    "    return c\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment Pulling Functions\n",
    "def word_time_list(lst):\n",
    "    start = []\n",
    "    end = []\n",
    "    for item in lst:\n",
    "        start.append(item[1])\n",
    "        end.append(item[2])\n",
    "    return start, end\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return (np.abs(np.asarray(array) - value)).argmin()\n",
    "\n",
    "def get_seg(st, e, name, start, end, trans=None):\n",
    "    st_id = find_nearest(start, float(st))\n",
    "    en_id = find_nearest(end, float(e)+float(st))\n",
    "    if trans is not None:\n",
    "        script = trans.split(' ')[st_id:en_id+1]\n",
    "        return [name, ' '.join(script), (float(st), float(st)+float(e))]\n",
    "    return st_id, en_id, name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate BERT Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rttm_path = './rttm/' # gold standard diarization\n",
    "#rttm_path = './rdsv/' # RDSV predicted diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_BERT = {}\n",
    "for wav in set_dict['t']:\n",
    "    case = wav.split('.')[0]\n",
    "\n",
    "    if 'rdsv' in rttm_path:\n",
    "        with open(rttm_path+case+'_rdsv.rttm', newline='\\n') as f:\n",
    "            reader = csv.reader(f)\n",
    "            case_diary = list(reader)        \n",
    "    else:\n",
    "        with open(rttm_path+case+'.rttm', newline='\\n') as f:\n",
    "            reader = csv.reader(f)\n",
    "            case_diary = list(reader)\n",
    "\n",
    "    oyez_toBERT = []\n",
    "    for item in case_diary:\n",
    "        temp = item[0].split(' ')\n",
    "        if temp[7][-14:]=='scotus_justice' and float(temp[4])>3:\n",
    "            oyez_toBERT.append(get_seg(temp[3], temp[4], temp[7], ostl, oetl, trans=''.join(oyez)))\n",
    "            \n",
    "    to_BERT[case]= {'OYEZ': oyez_toBERT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rttm_path.split('/')[1]=='rttm':\n",
    "    with open(\"./toBERT_oyez.json\", \"w\") as outfile: \n",
    "        json.dump(to_BERT, outfile)\n",
    "else:\n",
    "    with open(\"./toBERT_\"+rttm_path.split('/')[1]+\".json\", \"w\") as outfile: \n",
    "        json.dump(to_BERT, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
