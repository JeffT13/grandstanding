{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, string, os\n",
    "import jiwer\n",
    "import numpy as np\n",
    "from scipy.stats import describe\n",
    "\n",
    "trans_path = './oyez/'\n",
    "ibm_path = './ibm_trans/'\n",
    "google_path = './google_trans/'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./set_dict.json') as f:\n",
    "    set_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ibm(case, pth=ibm_path, sec=1800):\n",
    "    segs = [p for p in os.listdir(pth) if case+'_' in p]\n",
    "    ibm_list = []\n",
    "    wd = []\n",
    "    for seg in segs:\n",
    "        split = int(seg.split('_')[1])\n",
    "        add = split*sec\n",
    "        with open(pth+seg) as f:\n",
    "            api = json.load(f)\n",
    "            \n",
    "        for i in api['results']:\n",
    "            tsl = []\n",
    "            for j in i['alternatives'][0]['timestamps']:\n",
    "                tsl.append( [j[0], (j[1]+add), (j[2]+add)] )\n",
    "            i['alternatives'][0]['timestamps'] = tsl\n",
    "            wd.append(tsl)\n",
    "        ibm_list.append(api['results'])\n",
    "\n",
    "    ibm = [j for i in ibm_list for j in i]\n",
    "    \n",
    "    trans_times = []\n",
    "    for i in ibm:\n",
    "        trans = i['alternatives'][0]['transcript']\n",
    "        start = i['alternatives'][0]['timestamps'][0][1]\n",
    "        end = i['alternatives'][0]['timestamps'][-1][-1]\n",
    "        trans_times.append((start, end, trans))\n",
    "\n",
    "    ibm_transcript = []\n",
    "    for v in trans_times:\n",
    "        ibm_transcript.append(v[-1])\n",
    "    return ibm_transcript, [j for i in wd for j in i]\n",
    "\n",
    "\n",
    "def load_google(case, pth=google_path):\n",
    "    with open(google_path+case+'.json') as f:\n",
    "        file = json.load(f)\n",
    "    g = []\n",
    "    wd = []\n",
    "    for k in file.keys():\n",
    "        g.append(file[k][0])\n",
    "        wd.append(file[k][2])\n",
    "    return g, [j for i in wd for j in i]\n",
    "\n",
    "def load_oyez(case, pth=trans_path):    \n",
    "    f = open(pth+case+'.txt','r')\n",
    "    k = f.readlines()\n",
    "    f.close()\n",
    "    oyez = []\n",
    "    wd = []\n",
    "    for u in k:\n",
    "        if len(u)>=3: # check for filler lines\n",
    "            t0, t1, spkr = u.split(' ')[0:3]\n",
    "            text = u.split(spkr)[-1]\n",
    "            oyez.append(text)\n",
    "            temp = text.split(' ')\n",
    "            stp = ((float(t1)-float(t0))/len(temp))\n",
    "            seq = [float(t0)+(stp*i) for i in range(len(temp))]\n",
    "            for idx, time in enumerate(seq):\n",
    "                if temp[idx]!='':\n",
    "                    wd.append([temp[idx], time, time+(stp-.0001)])       \n",
    "    return oyez, wd\n",
    "\n",
    "def clean_trans(lst):\n",
    "    clean  = ''.join(lst)\n",
    "    c = clean.translate(str.maketrans('', '', string.punctuation))\n",
    "    c = c.replace('\\n', '')\n",
    "    c = c.lower()\n",
    "    return c\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment Pulling Functions\n",
    "def word_time_list(lst):\n",
    "    start = []\n",
    "    end = []\n",
    "    for item in lst:\n",
    "        start.append(item[1])\n",
    "        end.append(item[2])\n",
    "    return start, end\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return (np.abs(np.asarray(array) - value)).argmin()\n",
    "\n",
    "def get_seg(st, e, name, start, end, trans=None):\n",
    "    st_id = find_nearest(start, float(st))\n",
    "    en_id = find_nearest(end, float(e)+float(st))\n",
    "    if trans is not None:\n",
    "        script = trans.split(' ')[st_id:en_id+1]\n",
    "        return [name, ' '.join(script), (float(st), float(st)+float(e))]\n",
    "    return st_id, en_id, name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Speech2Text API Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Case: 17-1705\n",
      "Lengths: 11819 10758 10936\n",
      "WER: {'IBM': 0.19497915373015168, 'GOOG': 0.11647298855672847}\n",
      "Processing Case: 17-530\n",
      "Lengths: 9107 8753 8857\n",
      "WER: {'IBM': 0.17274774774774776, 'GOOG': 0.08963963963963964}\n",
      "Processing Case: 17-459\n",
      "Lengths: 10888 10192 10417\n",
      "WER: {'IBM': 0.16965055050263284, 'GOOG': 0.09832455720440401}\n",
      "Processing Case: 17-1174\n",
      "Lengths: 10885 10472 10585\n",
      "WER: {'IBM': 0.1767257638626933, 'GOOG': 0.0950584685024519}\n",
      "Processing Case: 17-1272\n",
      "Lengths: 10756 10290 10388\n",
      "WER: {'IBM': 0.16077755434262186, 'GOOG': 0.09451307095662166}\n",
      "Processing Case: 17-130\n",
      "Lengths: 10768 10227 10504\n",
      "WER: {'IBM': 0.17370846936815826, 'GOOG': 0.0893988861148454}\n",
      "Processing Case: 17-269\n",
      "Lengths: 12192 11435 11575\n",
      "WER: {'IBM': 0.1845917845576956, 'GOOG': 0.10533492415203681}\n",
      "Processing Case: 17-1104\n",
      "Lengths: 10964 10462 10623\n",
      "WER: {'IBM': 0.16443236148870347, 'GOOG': 0.09093465829192837}\n",
      "Processing Case: 17-571\n",
      "Lengths: 10726 10312 10763\n",
      "WER: {'IBM': 0.16096385542168676, 'GOOG': 0.08481927710843373}\n",
      "Processing Case: 17-1606\n",
      "Lengths: 9653 9222 9518\n",
      "WER: {'IBM': 0.15605639820551165, 'GOOG': 0.08417004913480025}\n",
      "Processing Case: 17-1042\n",
      "Lengths: 9360 9124 9359\n",
      "WER: {'IBM': 0.18780061215566243, 'GOOG': 0.0914954088325317}\n",
      "Processing Case: 17-43\n",
      "Lengths: 10555 9819 10058\n",
      "WER: {'IBM': 0.1692035745850928, 'GOOG': 0.10988903073750368}\n",
      "Processing Case: 17-1107\n",
      "Lengths: 11560 10894 11197\n",
      "WER: {'IBM': 0.18806104129263915, 'GOOG': 0.10341113105924596}\n",
      "Processing Case: 17-1307\n",
      "Lengths: 11427 10963 11095\n",
      "WER: {'IBM': 0.1570596145226356, 'GOOG': 0.08354997758852532}\n",
      "Processing Case: 17-1594\n",
      "Lengths: 10449 10115 10444\n",
      "WER: {'IBM': 0.15090464547677263, 'GOOG': 0.080880195599022}\n",
      "Processing Case: 17-1091\n",
      "Lengths: 10077 9580 9992\n",
      "WER: {'IBM': 0.16890300112670287, 'GOOG': 0.08491242445969477}\n",
      "Processing Case: 17-6086\n",
      "Lengths: 9581 9245 9363\n",
      "WER: {'IBM': 0.15187841164508187, 'GOOG': 0.08690998608583966}\n",
      "Processing Case: 17-1702\n",
      "Lengths: 11452 10741 11018\n",
      "WER: {'IBM': 0.18104860731840525, 'GOOG': 0.11369015110140178}\n",
      "Processing Case: 17-290\n",
      "Lengths: 10447 10144 10360\n",
      "WER: {'IBM': 0.15122334676230717, 'GOOG': 0.08912253119779896}\n",
      "Processing Case: 17-5554\n",
      "Lengths: 10266 9569 9771\n",
      "WER: {'IBM': 0.16129685916919959, 'GOOG': 0.10192502532928065}\n",
      "Processing Case: 17-5716\n",
      "Lengths: 10945 10650 11007\n",
      "WER: {'IBM': 0.18424004486819967, 'GOOG': 0.08833426808749299}\n",
      "Processing Case: 17-1229\n",
      "Lengths: 10140 9713 10013\n",
      "WER: {'IBM': 0.17078126587422535, 'GOOG': 0.09712486030681702}\n",
      "Processing Case: 17-71\n",
      "Lengths: 10361 9662 9994\n",
      "WER: {'IBM': 0.17888563049853373, 'GOOG': 0.10769541915259379}\n",
      "Processing Case: 17-765\n",
      "Lengths: 11713 11260 11492\n",
      "WER: {'IBM': 0.17568867512024486, 'GOOG': 0.07966768692610407}\n",
      "Processing Case: 17-773\n",
      "Lengths: 10056 9527 9861\n",
      "WER: {'IBM': 0.2337782340862423, 'GOOG': 0.13367556468172484}\n"
     ]
    }
   ],
   "source": [
    "trans_wer = {}\n",
    "ires = []\n",
    "gres = []\n",
    "for wav in set_dict['t']:\n",
    "    case = wav.split('.')[0]\n",
    "    if verbose:\n",
    "        print(\"Processing Case:\", case)\n",
    "    #load Oyez Transcript\n",
    "    oyez, wl = load_oyez(case, trans_path)\n",
    "    ground_truth = clean_trans(oyez)\n",
    "\n",
    "    #load IBM transcript\n",
    "    ibm, iwd = load_ibm(case, ibm_path)\n",
    "    i = clean_trans(ibm)\n",
    "\n",
    "    #load Google\n",
    "    google, gwd = load_google(case, google_path)\n",
    "    g = clean_trans(google)\n",
    "\n",
    "    i_err = jiwer.wer(ground_truth, i)\n",
    "    g_err = jiwer.wer(ground_truth, g)\n",
    "\n",
    "    ires.append(i_err)\n",
    "    gres.append(g_err)\n",
    "\n",
    "    trans_wer[case] = {'IBM': i_err, 'GOOG': g_err}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Lengths:\", len(ground_truth.split(' ')), len(g.split(' ')), len(i.split(' ')))\n",
    "        print(\"WER:\", trans_wer[case])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=25, minmax=(0.15090464547677263, 0.2337782340862423), mean=0.17301548814918197, variance=0.00031276932294871027, skewness=1.536009818660894, kurtosis=3.60327914386448)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(ires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=25, minmax=(0.07966768692610407, 0.13367556468172484), mean=0.0960380072322987, variance=0.00016770994183634756, skewness=1.1043509574977306, kurtosis=0.9542885813840596)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(gres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./S2T_API_WER.json', 'w') as outfile:  \n",
    "    json.dump(trans_wer, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate BERT Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rttm_path = './rttm/' # gold standard diarization\n",
    "#rttm_path = './rdsv/' # RDSV predicted diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_BERT = {}\n",
    "for wav in set_dict['t']:\n",
    "    case = wav.split('.')[0]\n",
    "        \n",
    "    if 'rdsv' in rttm_path:\n",
    "        with open(rttm_path+case+'_rdsv.rttm', newline='\\n') as f:\n",
    "            reader = csv.reader(f)\n",
    "            case_diary = list(reader)        \n",
    "    else:\n",
    "        with open(rttm_path+case+'.rttm', newline='\\n') as f:\n",
    "            reader = csv.reader(f)\n",
    "            case_diary = list(reader)\n",
    "\n",
    "    oyez, owd = load_oyez(case, trans_path)        \n",
    "    ibm, iwd = load_ibm(case, ibm_path)\n",
    "    google, gwd = load_google(case, google_path)\n",
    "    \n",
    "    ostl, oetl = word_time_list(owd)   \n",
    "    istl, ietl = word_time_list(iwd)\n",
    "    gstl, getl = word_time_list(gwd)\n",
    "    \n",
    "    oyez_toBERT = []\n",
    "    ibm_toBERT = []\n",
    "    goog_toBERT = []\n",
    "    for item in case_diary:\n",
    "        temp = item[0].split(' ')\n",
    "        if temp[7][-14:]=='scotus_justice' and float(temp[4])>3:\n",
    "            oyez_toBERT.append(get_seg(temp[3], temp[4], temp[7], ostl, oetl, trans=''.join(oyez)))\n",
    "            ibm_toBERT.append(get_seg(temp[3], temp[4], temp[7], istl, ietl, trans=''.join(ibm)))\n",
    "            goog_toBERT.append(get_seg(temp[3], temp[4], temp[7], gstl, getl, trans=''.join(google)))\n",
    "            \n",
    "    to_BERT[case]= {'OYEZ': oyez_toBERT, 'IBM': ibm_toBERT, 'GOOG': goog_toBERT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rttm_path.split('/')[1]=='rttm':\n",
    "    with open(\"./toBERT_oyez.json\", \"w\") as outfile: \n",
    "        json.dump(to_BERT, outfile)\n",
    "else:\n",
    "    with open(\"./toBERT_\"+rttm_path.split('/')[1]+\".json\", \"w\") as outfile: \n",
    "        json.dump(to_BERT, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
